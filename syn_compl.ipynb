{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Критерии syntactic complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Количество слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from model import Model\n",
    "import re\n",
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция, которая добавляет пробелы после .?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def space(string):\n",
    "    string = re.sub('([a-zA-Z]| )([\\.\\?!])', '\\\\1\\\\2 ', string)\n",
    "    string = re.sub('  +', ' ', string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция, которая парсит текст udpipe. На выходе получается строка с форматом 'conllu'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_parsed_text(model_name, text_path):\n",
    "    model = Model(model_name)\n",
    "    text = open(text_path, 'r')\n",
    "    text = text.read()\n",
    "    text = space(text)\n",
    "    sentences = model.tokenize(text)\n",
    "    for s in sentences:\n",
    "        model.tag(s)\n",
    "        model.parse(s)\n",
    "    output = model.write(sentences, \"conllu\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция, которая считает токены в тексте. Не считаются знаки препинания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_tokens(parsed_text):\n",
    "    num_tokens = 0\n",
    "    lst_str = parsed_text.split('\\n')\n",
    "    for every_str in lst_str:\n",
    "        #print(every_str)\n",
    "        if ('PUNCT' not in every_str) and every_str.startswith('#') == False:\n",
    "            #print(every_str)\n",
    "            num_tokens += 1\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parsed_text = get_parsed_text('english-partut-ud-2.0-170801.udpipe', '/Users/irene/Downloads/exam2014/AAl_1_1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция, которая считает глубину дерева."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def order_head(parsed_sent):\n",
    "    sent_lst = parsed_sent.split('\\n')\n",
    "    #print(sent_lst[0])\n",
    "    order_head_lst = []\n",
    "    for token in sent_lst:\n",
    "        token = re.sub(r'\\|', '$', token)\n",
    "        order = re.search('([0-9]+)\\t', token).group(1)\n",
    "        #print(order)\n",
    "        head = re.search('.+\\t.+\\t([0-9]+)', token).group(1)\n",
    "        #print(head)\n",
    "        token = re.search('^[0-9]+\\t(.+?)\\t', token).group(1)\n",
    "        order_head_lst.append((int(order), int(head), token))\n",
    "    return order_head_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_root(order_head_lst):\n",
    "    for every_order_head in order_head_lst:\n",
    "        if every_order_head[1] == 0:\n",
    "            root = every_order_head\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def root_children(parsed_sent):\n",
    "    order_head_lst = order_head(parsed_sent)\n",
    "    #print(order_head_lst)\n",
    "    root = find_root(order_head_lst)\n",
    "    chains = []\n",
    "    for every_order_head in order_head_lst:\n",
    "        if every_order_head[1] == root[0]:\n",
    "            chains.append([root[0], every_order_head[0]])\n",
    "    return chains, order_head_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chains_heads(chains, order_head_lst):\n",
    "    length_chains = len(chains)\n",
    "    i = 0\n",
    "    for chain in chains:\n",
    "        if i < length_chains:\n",
    "            heads = []\n",
    "            if 'stop' not in chain:\n",
    "                for order_head in order_head_lst:\n",
    "                    if chain[-1] == order_head[1]:\n",
    "                        heads.append(order_head[0])\n",
    "                if heads == [] and 'stop' not in chain:\n",
    "                    chain.append('stop')\n",
    "                else:\n",
    "                    ind_head = 0\n",
    "                    for head in heads:\n",
    "                        new_chain = copy.copy(chain)[:-1]\n",
    "                        if ind_head == 0:\n",
    "                            chain.append(head)\n",
    "                            ind_head += 1\n",
    "                        else:\n",
    "                            new_chain.append(head)\n",
    "                            chains.append(new_chain)\n",
    "        i += 1\n",
    "    while all(item[-1] == 'stop' for item in chains) is False:\n",
    "        count_depth_for_one_sent(chains, order_head_lst)\n",
    "    return chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_max_depth_for_one_sent(sent):\n",
    "    chains, order_head_lst = root_children(sent)\n",
    "    chains = chains_heads(chains, order_head_lst)\n",
    "    depths = []\n",
    "    #print(chains)\n",
    "    for chain in chains:\n",
    "        depths.append(len(chain)-2)\n",
    "    return max(depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_depths_for_one_text(parsed_text):\n",
    "    sent_lst = re.findall('(1\\t.+?)\\n\\n', parsed_text, re.DOTALL)\n",
    "    max_depths = []\n",
    "    for sent in sent_lst:\n",
    "        max_depths.append(count_max_depth_for_one_sent(sent))\n",
    "    return max_depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def av_depth_for_one_text(parsed_text):\n",
    "    max_depths = count_depths_for_one_text(parsed_text)\n",
    "    return np.mean(max_depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_depth_for_one_text(parsed_text):\n",
    "    max_depths = count_depths_for_one_text(parsed_text)\n",
    "    return np.max(max_depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def min_depth_for_one_text(parsed_text):\n",
    "    max_depths = count_depths_for_one_text(parsed_text)\n",
    "    return np.min(max_depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 5, 4, 6, 5, 3, 3, 4, 5, 3, 4]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_depths_for_one_text(parsed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.3636363636363633"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_depth_for_one_text(parsed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth_for_one_text(parsed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_depth_for_one_text(parsed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Количество зависимых клауз: acl, acl:relcl, advcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Возвращает словарь, где ключ - номер предложения, значения - массив [кол-во acl, кол-во acl:relcl, кол-во advcl]\n",
    "def count_dependent_sent(parsed_text):\n",
    "    sent_lst = re.findall('(1\\t.+?)\\n\\n', parsed_text, re.DOTALL)\n",
    "    num_sent = 1\n",
    "    d_sent = {}\n",
    "    for sent in sent_lst:\n",
    "        acl = len(re.findall('\\t(acl)\\t',sent))\n",
    "        relcl = len(re.findall('\\t(acl:relcl)\\t',sent))\n",
    "        advcl = len(re.findall('\\t(advcl)\\t',sent))\n",
    "        d_sent[num_sent] = [acl, relcl, advcl]\n",
    "        num_sent += 1\n",
    "    return d_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [2, 0, 0],\n",
       " 2: [0, 0, 1],\n",
       " 3: [0, 0, 0],\n",
       " 4: [0, 1, 0],\n",
       " 5: [1, 0, 0],\n",
       " 6: [0, 0, 0],\n",
       " 7: [0, 0, 0],\n",
       " 8: [0, 0, 1],\n",
       " 9: [1, 0, 0],\n",
       " 10: [0, 0, 0],\n",
       " 11: [0, 0, 1]}"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_dependent_sent(parsed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
