{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Критерии syntactic complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Количество слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from model import Model\n",
    "import re\n",
    "import copy\n",
    "import numpy as np\n",
    "from spellchecker import check_spelling\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция, которая добавляет пробелы после .?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def space(string):\n",
    "    string = re.sub('([a-zA-Z]| )([\\.\\?!])', '\\\\1\\\\2 ', string)\n",
    "    string = re.sub(': ', ' : ', string)\n",
    "    string = re.sub('; ', ' ; ', string)\n",
    "    string = re.sub('  +', ' ', string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция, которая парсит текст udpipe. На выходе получается строка с форматом 'conllu'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_parsed_text(model_name, text_path):\n",
    "    model = Model(model_name)\n",
    "    text = open(text_path, 'r')\n",
    "    text = text.read()\n",
    "    text = check_spelling(text)\n",
    "    text = space(text)\n",
    "    sentences = model.tokenize(text)\n",
    "    for s in sentences:\n",
    "        model.tag(s)\n",
    "        model.parse(s)\n",
    "    output = model.write(sentences, \"conllu\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция, которая считает токены в тексте. Не считаются знаки препинания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_tokens(parsed_text):\n",
    "    num_tokens = 0\n",
    "    lst_str = parsed_text.split('\\n')\n",
    "    for every_str in lst_str:\n",
    "        #print(every_str)\n",
    "        if ('PUNCT' not in every_str) and every_str.startswith('#') == False:\n",
    "            #print(every_str)\n",
    "            num_tokens += 1\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#count_tokens(parsed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Глубина дерева"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция, которая считает глубину дерева."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def order_head(parsed_sent):\n",
    "    sent_lst = parsed_sent.split('\\n')\n",
    "    #print(sent_lst[0])\n",
    "    order_head_lst = []\n",
    "    for token in sent_lst:\n",
    "        token = re.sub(r'\\|', '$', token)\n",
    "        if '\\t_\\t_\\t_\\t_\\t_' not in token:\n",
    "            order = re.search('([0-9]+)\\t', token).group(1)\n",
    "        #print(order)\n",
    "            head = re.search('.+\\t.+\\t([0-9]+)', token).group(1)\n",
    "        #print(head)\n",
    "            token = re.search('^[0-9]+\\t(.+?)\\t', token).group(1)\n",
    "            order_head_lst.append((int(order), int(head), token))\n",
    "    return order_head_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_root(order_head_lst):\n",
    "    for every_order_head in order_head_lst:\n",
    "        if every_order_head[1] == 0:\n",
    "            root = every_order_head\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def root_children(parsed_sent):\n",
    "    order_head_lst = order_head(parsed_sent)\n",
    "    #print(order_head_lst)\n",
    "    root = find_root(order_head_lst)\n",
    "    chains = []\n",
    "    for every_order_head in order_head_lst:\n",
    "        if every_order_head[1] == root[0]:\n",
    "            chains.append([root[0], every_order_head[0]])\n",
    "    return chains, order_head_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chains_heads(chains, order_head_lst):\n",
    "    length_chains = len(chains)\n",
    "    i = 0\n",
    "    for chain in chains:\n",
    "        if i < length_chains:\n",
    "            heads = []\n",
    "            if 'stop' not in chain:\n",
    "                for order_head in order_head_lst:\n",
    "                    if chain[-1] == order_head[1]:\n",
    "                        heads.append(order_head[0])\n",
    "                if heads == [] and 'stop' not in chain:\n",
    "                    chain.append('stop')\n",
    "                else:\n",
    "                    ind_head = 0\n",
    "                    for head in heads:\n",
    "                        new_chain = copy.copy(chain)[:-1]\n",
    "                        if ind_head == 0:\n",
    "                            chain.append(head)\n",
    "                            ind_head += 1\n",
    "                        else:\n",
    "                            new_chain.append(head)\n",
    "                            chains.append(new_chain)\n",
    "        i += 1\n",
    "    while all(item[-1] == 'stop' for item in chains) is False:\n",
    "        chains_heads(chains, order_head_lst)\n",
    "    return chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_max_depth_for_one_sent(sent):\n",
    "    chains, order_head_lst = root_children(sent)\n",
    "    chains = chains_heads(chains, order_head_lst)\n",
    "    depths = []\n",
    "    #print(chains)\n",
    "    for chain in chains:\n",
    "        depths.append(len(chain)-2)\n",
    "    return max(depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_depths_for_one_text(parsed_text):\n",
    "    sent_lst = re.findall('(1\\t.+?)\\n\\n', parsed_text, re.DOTALL)\n",
    "    max_depths = []\n",
    "    for sent in sent_lst:\n",
    "        #print(sent)\n",
    "        max_depths.append(count_max_depth_for_one_sent(sent))\n",
    "    return max_depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def av_depth_for_one_text(parsed_text):\n",
    "    max_depths = count_depths_for_one_text(parsed_text)\n",
    "    return round(np.mean(max_depths), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_depth_for_one_text(parsed_text):\n",
    "    max_depths = count_depths_for_one_text(parsed_text)\n",
    "    return round(np.max(max_depths),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def min_depth_for_one_text(parsed_text):\n",
    "    max_depths = count_depths_for_one_text(parsed_text)\n",
    "    return round(np.min(max_depths), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.71"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#av_depth_for_one_text(parsed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max_depth_for_one_text(parsed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#min_depth_for_one_text(parsed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Количество зависимых клауз: acl, acl:relcl, advcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Возвращает словарь, где ключ - номер предложения, значения - массив [кол-во acl, кол-во acl:relcl, кол-во advcl]\n",
    "def count_dependent_sent(parsed_text):\n",
    "    sent_lst = re.findall('(1\\t.+?)\\n\\n', parsed_text, re.DOTALL)\n",
    "    num_sent = 1\n",
    "    d_sent = {}\n",
    "    for sent in sent_lst:\n",
    "        acl = len(re.findall('\\t(acl)\\t',sent))\n",
    "        relcl = len(re.findall('\\t(acl:relcl)\\t',sent))\n",
    "        advcl = len(re.findall('\\t(advcl)\\t',sent))\n",
    "        d_sent[num_sent] = [acl, relcl, advcl]\n",
    "        num_sent += 1\n",
    "    return d_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_dependent_sent_text(parsed_text):\n",
    "    d_sent = count_dependent_sent(parsed_text)\n",
    "    acl = 0\n",
    "    rel_cl = 0\n",
    "    advcl = 0\n",
    "    for sent in d_sent:\n",
    "        acl = acl + d_sent[sent][0]\n",
    "        rel_cl = rel_cl + d_sent[sent][1]\n",
    "        advcl = advcl + d_sent[sent][2]\n",
    "    return acl, rel_cl, advcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_acl(parsed_text):\n",
    "    acl = count_dependent_sent_text(parsed_text)[0]\n",
    "    return acl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_acl_relcl(parsed_text):\n",
    "    acl_relcl = count_dependent_sent_text(parsed_text)[1]\n",
    "    return acl_relcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_advcl(parsed_text):\n",
    "    advcl = count_dependent_sent_text(parsed_text)[2]\n",
    "    return advcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_acl(parsed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_acl_relcl(parsed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_advcl(parsed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Количество предложений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_sent(parsed_text):\n",
    "    sent_lst = re.findall('(1\\t.+?)\\n\\n', parsed_text, re.DOTALL)\n",
    "    return len(sent_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count_sent(parsed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 5. Количество клауз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parsing_things(string):\n",
    "    token = re.search('[0-9]+\\t(.+?)\\t', string).group(1)\n",
    "    order = re.search('([0-9]+)\\t', string).group(1)\n",
    "    head = re.search('\\t([0-9]+)\\t', string).group(1)\n",
    "    rel_type = re.search('\\t[0-9]+\\t(.+?)\\t', string).group(1)\n",
    "    pos = re.search('[0-9]+\\t.+?\\t.+?\\t(.+?)\\t', string).group(1)\n",
    "    #grammar = re.search('[VERB|AUX]\\t.+?\\t(.+?)\\t', every_str).group(1)\n",
    "    return order, token, head, rel_type, pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция, которая возвращает словарь, где ключи - номера предложений, а значения - количество клауз."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***There was a woman next door, and she was a singer.*** - 2 T-units, 2 clauses\n",
    "\n",
    "***There was a woman next door who was a singer.*** - 1 T-units, 2 clauses\n",
    "\n",
    "***But while they were trying they killed a whale and used the oil for the lamps.*** - 2 clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_clauses_every_sent(parsed_text):\n",
    "    sent_lst = re.findall('(1\\t.+?)\\n\\n', parsed_text, re.DOTALL)\n",
    "    verb_cl = {}\n",
    "    all_num_sent = count_sent(parsed_text)\n",
    "    for sent in range(1, all_num_sent+1):\n",
    "        verb_cl[sent] = []\n",
    "    num_sent = 1\n",
    "    for every_sent in sent_lst:\n",
    "        lst_str = every_sent.split('\\n')\n",
    "        for every_str in lst_str:\n",
    "            if ('VerbForm=Fin' in every_str):\n",
    "                sent_id = str(num_sent)\n",
    "                order, token, head, rel_type, pos = parsing_things(every_str)\n",
    "                if head not in verb_cl[int(sent_id)] and rel_type != 'conj':\n",
    "                    verb_cl[int(sent_id)].append([order, head])\n",
    "        num_sent += 1\n",
    "    for key, value in verb_cl.items():\n",
    "        if verb_cl[key] == []:\n",
    "            verb_cl[key] = [None]\n",
    "        verb_cl[key] = len(verb_cl[key])\n",
    "    return verb_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_clauses(parsed_text):\n",
    "    verb_cl = count_clauses_every_sent(parsed_text)\n",
    "    num_cl = 0\n",
    "    for key, value in verb_cl.items():\n",
    "        num_cl = num_cl + value\n",
    "    return num_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#count_clauses(parsed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Количество T-юнитов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_subjects(sentence):\n",
    "    lst_str = sentence.split('\\n')\n",
    "    maybe_depends = []\n",
    "    for every_str in lst_str:\n",
    "        finding = re.search('PRON|NOUN', every_str)\n",
    "        if '_\\t_\\t_\\t_\\t_' not in every_str:\n",
    "            order, token, head, rel_type, pos = parsing_things(every_str)\n",
    "            if finding is not None:\n",
    "                maybe_depends.append(rel_type)\n",
    "    return maybe_depends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_tunits_every_sent(parsed_text):\n",
    "    verb_cl = count_clauses_every_sent(parsed_text)\n",
    "    sent_lst = re.findall('(1\\t.+?)\\n\\n', parsed_text, re.DOTALL)\n",
    "    for key, value in verb_cl.items():\n",
    "        subjects = find_subjects(sent_lst[key-1])\n",
    "        acl_relcl = subjects.count('acl:relcl')\n",
    "        acl = subjects.count('acl')\n",
    "        advcl = subjects.count('advcl')\n",
    "        depends = acl_relcl + acl + advcl\n",
    "        verb_cl[key] = verb_cl[key]-depends\n",
    "    return verb_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_tunits(parsed_text):\n",
    "    verb_cl = count_tunits_every_sent(parsed_text)\n",
    "    num_t = 0\n",
    "    for key, value in verb_cl.items():\n",
    "        num_t = num_t + value\n",
    "    return num_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count_tunits(parsed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Количество сложных T-юнитов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_complex_tunit(parsed_text):\n",
    "    return count_clauses(parsed_text)-count_tunits(parsed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count_complex_tunit(parsed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Количество сочинительных фраз"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция возвращает все сочинительные союзы (их вершины): ключи - номера предложений, значения - массив из вершин союзов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_all_coord(parsed_text):\n",
    "    sent_lst = re.findall('(1\\t.+?)\\n\\n', parsed_text, re.DOTALL)\n",
    "    all_num_sent = count_sent(parsed_text)\n",
    "    cp = {}\n",
    "    for sent in range(1, all_num_sent+1):\n",
    "        cp[sent] = []\n",
    "    num_sent = 1\n",
    "    for every_sent in sent_lst:\n",
    "        lst_str = every_sent.split('\\n')\n",
    "        for every_str in lst_str:\n",
    "            if '\\tcc\\t' in every_str:\n",
    "                order, token, head, rel_type, pos = parsing_things(every_str)\n",
    "                cp[int(num_sent)].append(head)\n",
    "        num_sent += 1\n",
    "    return cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция возвращает cловарь: ключи - номера предложений, значение - количество сочинительных фраз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def final_coord(parsed_text):\n",
    "    cp = find_all_coord(parsed_text)\n",
    "    sent_lst = re.findall('(1\\t.+?)\\n\\n', parsed_text, re.DOTALL)\n",
    "    all_num_sent = count_sent(parsed_text)\n",
    "    num_sent = 1\n",
    "    cp_final = {}\n",
    "    for sent in range(1, all_num_sent+1):\n",
    "        cp_final[sent] = 0\n",
    "    for every_sent in sent_lst:\n",
    "        #print('НОМЕР ПРЕДЛОЖЕНИЯ: ' + str(num_sent))\n",
    "        for every_coord_cp in cp[num_sent]:\n",
    "            #print('ВЕРШИНА СОЮЗА: ' + every_coord_cp)\n",
    "            finding2 = re.search('('+every_coord_cp+'\\t.+?\\tconj.+?)\\n', every_sent)\n",
    "            if finding2 is None:\n",
    "                continue\n",
    "            else:\n",
    "                order2, token2, head2, rel_type2, pos2 = parsing_things(finding2.group(0))\n",
    "                #print('2 СВЯЗУЮЩИЙ: ' + token2 + pos2)\n",
    "                finding1 = re.search('('+head2+'\\t.+?\\t[a-z]+.+?)\\n', every_sent)\n",
    "                order1, token1, head1, rel_type1, pos1 = parsing_things(finding1.group(0))\n",
    "                #print('1 СВЯЗУЮЩИЙ: ' + token1+pos1)\n",
    "                if pos2 == pos1:\n",
    "                    cp_final[num_sent] += 1 \n",
    "        num_sent += 1\n",
    "    return cp_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_coord(parsed_text):\n",
    "    cp_final = final_coord(parsed_text)\n",
    "    num_cp = 0\n",
    "    for key, value in cp_final.items():\n",
    "        num_cp = num_cp + value\n",
    "    return num_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#count_coord(parsed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Количество сложных именных групп"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complex nominals comprise (i) nouns plus adjective, possessive, prepositional phrase, relative clause, participle, or appositive, (ii) nominal clauses, and (iii) gerunds and infinitives in subject position (Cooper 1976)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Possessive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_possesive(parsed_text):\n",
    "    sent_lst = re.findall('(1\\t.+?)\\n\\n', parsed_text, re.DOTALL)\n",
    "    all_num_sent = count_sent(parsed_text)\n",
    "    poss = {}\n",
    "    for sent in range(1, all_num_sent+1):\n",
    "        poss[sent] = 0\n",
    "    num_sent = 1\n",
    "    for every_sent in sent_lst:\n",
    "        lst_str = every_sent.split('\\n')\n",
    "        for every_str in lst_str:\n",
    "            if 'nmod' in every_str:# включая nmod:poss\n",
    "                order, token, head, rel_type, pos = parsing_things(every_str)\n",
    "                poss[num_sent] = poss[num_sent] + 1\n",
    "        num_sent += 1\n",
    "    return poss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepositional phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_prep(parsed_text):\n",
    "    sent_lst = re.findall('(1\\t.+?)\\n\\n', parsed_text, re.DOTALL)\n",
    "    all_num_sent = count_sent(parsed_text)\n",
    "    poss = {}\n",
    "    for sent in range(1, all_num_sent+1):\n",
    "        poss[sent] = 0\n",
    "    num_sent = 1\n",
    "    for every_sent in sent_lst:\n",
    "        lst_str = every_sent.split('\\n')\n",
    "        for every_str in lst_str:\n",
    "            if 'ADP' in every_str:\n",
    "                order, token, head, rel_type, pos = parsing_things(every_str)\n",
    "                poss[num_sent] = poss[num_sent] + 1\n",
    "        num_sent += 1\n",
    "    return poss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nouns plus adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_nouns(parsed_text):\n",
    "    sent_lst = re.findall('(1\\t.+?)\\n\\n', parsed_text, re.DOTALL)\n",
    "    all_num_sent = count_sent(parsed_text)\n",
    "    vp = {}\n",
    "    for sent in range(1, all_num_sent+1):\n",
    "        vp[sent] = []\n",
    "    num_sent = 1\n",
    "    for every_sent in sent_lst:\n",
    "        lst_str = every_sent.split('\\n')\n",
    "        for every_str in lst_str:\n",
    "            if 'NOUN' in every_str:\n",
    "                order, token, head, rel_type, pos = parsing_things(every_str)\n",
    "                vp[num_sent].append(order)\n",
    "        num_sent += 1\n",
    "    return vp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_adjs(parsed_text):\n",
    "    sent_lst = re.findall('(1\\t.+?)\\n\\n', parsed_text, re.DOTALL)\n",
    "    all_num_sent = count_sent(parsed_text)\n",
    "    vp = {}\n",
    "    for sent in range(1, all_num_sent+1):\n",
    "        vp[sent] = []\n",
    "    num_sent = 1\n",
    "    for every_sent in sent_lst:\n",
    "        lst_str = every_sent.split('\\n')\n",
    "        for every_str in lst_str:\n",
    "            if 'ADJ' in every_str:\n",
    "                order, token, head, rel_type, pos = parsing_things(every_str)\n",
    "                vp[num_sent].append(head)\n",
    "        num_sent += 1\n",
    "    return vp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adj_noun(parsed_text):\n",
    "    adjs = find_adjs(parsed_text)\n",
    "    nouns = find_nouns(parsed_text)\n",
    "    adj_noun = {}\n",
    "    for key in adjs:\n",
    "        adj_noun[key] = len([i for i, j in zip(adjs[key], nouns[key]) if i == j])\n",
    "    return adj_noun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gerunds and infinitives in subject position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_ger_inf(parsed_text):\n",
    "    sent_lst = re.findall('(1\\t.+?)\\n\\n', parsed_text, re.DOTALL)\n",
    "    all_num_sent = count_sent(parsed_text)\n",
    "    poss = {}\n",
    "    for sent in range(1, all_num_sent+1):\n",
    "        poss[sent] = 0\n",
    "    num_sent = 1\n",
    "    for every_sent in sent_lst:\n",
    "        lst_str = every_sent.split('\\n')\n",
    "        for every_str in lst_str:\n",
    "            if 'VerbForm=Ger' in every_str or 'VerbForm=Inf' in every_str and 'xcomp' not in every_str:\n",
    "                order, token, head, rel_type, pos = parsing_things(every_str)\n",
    "                poss[num_sent] = poss[num_sent] + 1\n",
    "        num_sent += 1\n",
    "    return poss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nouns plus participle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_parts(parsed_text):\n",
    "    sent_lst = re.findall('(1\\t.+?)\\n\\n', parsed_text, re.DOTALL)\n",
    "    all_num_sent = count_sent(parsed_text)\n",
    "    vp = {}\n",
    "    for sent in range(1, all_num_sent+1):\n",
    "        vp[sent] = []\n",
    "    num_sent = 1\n",
    "    for every_sent in sent_lst:\n",
    "        lst_str = every_sent.split('\\n')\n",
    "        for every_str in lst_str:\n",
    "            if 'VerbForm=Part' in every_str:\n",
    "                order, token, head, rel_type, pos = parsing_things(every_str)\n",
    "                vp[num_sent].append(head)\n",
    "        num_sent += 1\n",
    "    return vp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parts_noun(parsed_text):\n",
    "    parts = find_parts(parsed_text)\n",
    "    nouns = find_nouns(parsed_text)\n",
    "    adj_noun = {}\n",
    "    for key in parts:\n",
    "        adj_noun[key] = len([i for i, j in zip(parts[key], nouns[key]) if i == j])\n",
    "    return adj_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count(d):\n",
    "    num = 0\n",
    "    for key, value in d.items():\n",
    "        num = num + value\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_np(parsed_text):\n",
    "    poss = count(find_possesive(parsed_text))\n",
    "    prep_ph = count(find_prep(parsed_text))\n",
    "    adj_n = count(adj_noun(parsed_text))\n",
    "    ger_inf = count(find_ger_inf(parsed_text))\n",
    "    part_n = count(parts_noun(parsed_text))\n",
    "    return poss, prep_ph, adj_n, ger_inf, part_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#count_np(parsed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Количество глагольных групп"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_verbs(parsed_text):\n",
    "    sent_lst = re.findall('(1\\t.+?)\\n\\n', parsed_text, re.DOTALL)\n",
    "    all_num_sent = count_sent(parsed_text)\n",
    "    vp = {}\n",
    "    for sent in range(1, all_num_sent+1):\n",
    "        vp[sent] = []\n",
    "    num_sent = 1\n",
    "    for every_sent in sent_lst:\n",
    "        lst_str = every_sent.split('\\n')\n",
    "        for every_str in lst_str:\n",
    "            if 'VERB' in every_str or 'AUX' in every_str:\n",
    "                order, token, head, rel_type, pos = parsing_things(every_str)\n",
    "                vp[num_sent].append(order)\n",
    "        num_sent += 1\n",
    "    return vp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_vp(parsed_text):\n",
    "    vp = find_verbs(parsed_text)\n",
    "    sent_lst = re.findall('(1\\t.+?)\\n\\n', parsed_text, re.DOTALL)\n",
    "    all_num_sent = count_sent(parsed_text)\n",
    "    num_sent = 1\n",
    "    vp_final = {}\n",
    "    for sent in range(1, all_num_sent+1):\n",
    "        vp_final[sent] = 0\n",
    "    for every_sent in sent_lst:\n",
    "        #print('НОМЕР ПРЕДЛОЖЕНИЯ: ' + str(num_sent))\n",
    "        for every_vp in vp[num_sent]:\n",
    "            #print(every_vp)\n",
    "            finding_dep = re.findall('\\t'+every_vp+'\\t.+?\\t', every_sent)\n",
    "            finding_dep_2 = []\n",
    "            for every_finding_dep in finding_dep:\n",
    "                find_del = re.search('mark|nsubj|punct', every_finding_dep)\n",
    "                if find_del is None:\n",
    "                    finding_dep_2.append(every_finding_dep)\n",
    "            if finding_dep_2 != []:\n",
    "                vp_final[num_sent] += 1 \n",
    "        num_sent += 1\n",
    "    return vp_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_vp(parsed_text):\n",
    "    vp_final = find_vp(parsed_text)\n",
    "    num_vp = 0\n",
    "    for key, value in vp_final.items():\n",
    "        num_vp = num_vp + value\n",
    "    return num_vp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count_vp(parsed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Синтаксическая схожесть (части речи, леммы): среднее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def levenshtein(seq1, seq2):  \n",
    "    size_x = len(seq1) + 1\n",
    "    size_y = len(seq2) + 1\n",
    "    matrix = np.zeros ((size_x, size_y))\n",
    "    for x in range(size_x):\n",
    "        matrix [x, 0] = x\n",
    "    for y in range(size_y):\n",
    "        matrix [0, y] = y\n",
    "\n",
    "    for x in range(1, size_x):\n",
    "        for y in range(1, size_y):\n",
    "            if seq1[x-1] == seq2[y-1]:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1, y] + 1,\n",
    "                    matrix[x-1, y-1],\n",
    "                    matrix[x, y-1] + 1\n",
    "                )\n",
    "            else:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1,y] + 1,\n",
    "                    matrix[x-1,y-1] + 1,\n",
    "                    matrix[x,y-1] + 1\n",
    "                )\n",
    "    return (matrix[size_x - 1, size_y - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pos_lemma(parsed_text):\n",
    "    sent_lst = re.findall('(1\\t.+?)\\n\\n', parsed_text, re.DOTALL)\n",
    "    d = {}\n",
    "    for x in range(1, len(sent_lst)+1):\n",
    "        d[x] = [[], []]\n",
    "    #print(d[1][0])\n",
    "    i = 1\n",
    "    for sent in sent_lst:\n",
    "        lines = sent.split('\\n')\n",
    "        for line in lines:\n",
    "            #print(line)\n",
    "            pos = re.search('.+?\\t.+?\\t.+?\\t(.+?)\\t', line)\n",
    "            lemma = re.search('.+?\\t.+?\\t(.+?)\\t', line)\n",
    "            if pos != None and lemma != None:\n",
    "                d[i][0].append(pos.group(1))\n",
    "                d[i][1].append(lemma.group(1))\n",
    "            #print(pos)\n",
    "        i += 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simularity(parsed_text):\n",
    "    d = pos_lemma(parsed_text)\n",
    "    #print(len(d))\n",
    "    dd = {}\n",
    "    for x in range(1, len(d)+1):\n",
    "        dd[x] = [[], []]\n",
    "    i = 1\n",
    "    for key in d:\n",
    "        d[key][0]\n",
    "        for key2 in d:\n",
    "            #print(levenshtein(d[key][0], d[key2][0]))\n",
    "            if i != key2:\n",
    "                dd[i][0].append(levenshtein(d[key][0], d[key2][0]))\n",
    "                dd[i][1].append(levenshtein(d[key][1], d[key2][1]))\n",
    "        i += 1\n",
    "    print(dd)\n",
    "    for every in dd:\n",
    "        dd[every][0] = mean(dd[every][0])\n",
    "        dd[every][1] = mean(dd[every][1])\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pos_sim_min(parsed_text):\n",
    "    sim = simularity(parsed_text)\n",
    "    pos_min = []\n",
    "    for sent in sim:\n",
    "        pos_min.append(sim[sent][0])\n",
    "    return round(mean(pos_min), 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemma_sim_min(parsed_text):\n",
    "    sim = simularity(parsed_text)\n",
    "    lemma_min = []\n",
    "    print(sim)\n",
    "    for sent in sim:\n",
    "        lemma_min.append(sim[sent][1])\n",
    "    return round(mean(lemma_min), 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#simularity(parsed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Среднее количество токенов перед корнем предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokens_befor_root(parsed_text):\n",
    "    sent_lst = re.findall('(1\\t.+?)\\n\\n', parsed_text, re.DOTALL)\n",
    "    length = []\n",
    "    for sent in sent_lst:\n",
    "        lines = sent.split('\\n')\n",
    "        i = 0\n",
    "        for line in lines:\n",
    "            rel_type = re.search('.+?\\t.+?\\t.+?\\t.+?\\t.+?\\t.+?\\t.+?\\t(.+?)\\t', line)\n",
    "            if rel_type is not None:\n",
    "                if rel_type.group(1) == 'root':\n",
    "                    break\n",
    "            i += 1\n",
    "        length.append(i)\n",
    "    return round(mean(length), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.29"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokens_befor_root(parsed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Средняя длина предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_len_sent(parsed_text):\n",
    "    sent_lst = re.findall('(1\\t.+?)\\n\\n', parsed_text, re.DOTALL)\n",
    "    length = []\n",
    "    for sent in sent_lst:\n",
    "        lines = sent.split('\\n')\n",
    "        i = 0\n",
    "        for line in lines:\n",
    "            pos = re.search('.+?\\t.+?\\t.+?\\t(.+?)\\t', line)\n",
    "            if pos is not None:\n",
    "                if pos.group(1) != 'PUNCT':\n",
    "                    i += 1\n",
    "        length.append(i)\n",
    "    return round(mean(length), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.29"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mean_len_sent(parsed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parsed_text = get_parsed_text('english-partut-ud-2.0-170801.udpipe', '/Users/irene/Desktop/Курсовая/esseys/AAl_13_1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# newdoc\\n# newpar\\n# sent_id = 1\\n# text = The presented data shows us the percentage of people aged 65 and over in three different countries (USA, Sweden and Japan) in the second half of the 20Th century and up to 2040.\\n1\\tThe\\tthe\\tDET\\tRD\\tDefinite=Def|PronType=Art\\t3\\tdet\\t_\\t_\\n2\\tpresented\\tpresented\\tVERB\\tV\\tTense=Past|VerbForm=Part\\t3\\tacl\\t_\\t_\\n3\\tdata\\tdatum\\tNOUN\\tS\\tNumber=Plur\\t4\\tnsubj\\t_\\t_\\n4\\tshows\\tshow\\tVERB\\tV\\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\\t0\\troot\\t_\\t_\\n5\\tus\\tus\\tPRON\\tPE\\tNumber=Plur|Person=1|PronType=Prs\\t4\\tiobj\\t_\\t_\\n6\\tthe\\tthe\\tDET\\tRD\\tDefinite=Def|PronType=Art\\t7\\tdet\\t_\\t_\\n7\\tpercentage\\tpercentage\\tNOUN\\tS\\tNumber=Sing\\t4\\tobj\\t_\\t_\\n8\\tof\\tof\\tADP\\tE\\t_\\t9\\tcase\\t_\\t_\\n9\\tpeople\\tpeople\\tNOUN\\tS\\tNumber=Plur\\t7\\tnmod\\t_\\t_\\n10\\taged\\tag\\tVERB\\tV\\tTense=Past|VerbForm=Part\\t9\\tacl\\t_\\t_\\n11\\t65\\t65\\tNUM\\tN\\tNumType=Card\\t10\\tobj\\t_\\t_\\n12\\tand\\tand\\tCCONJ\\tCC\\t_\\t17\\tcc\\t_\\t_\\n13\\tover\\tover\\tADV\\tB\\t_\\t17\\tadvmod\\t_\\t_\\n14\\tin\\tin\\tADP\\tE\\t_\\t13\\tfixed\\t_\\t_\\n15\\tthree\\tthree\\tNUM\\tN\\tNumType=Card\\t17\\tnummod\\t_\\t_\\n16\\tdifferent\\tdifferent\\tADJ\\tA\\tDegree=Pos\\t17\\tamod\\t_\\t_\\n17\\tcountries\\tcountry\\tNOUN\\tS\\tNumber=Plur\\t10\\tconj\\t_\\t_\\n18\\t(\\t(\\tPUNCT\\tFB\\t_\\t19\\tpunct\\t_\\tSpaceAfter=No\\n19\\tUSA\\tUSA\\tPROPN\\tSP\\t_\\t17\\tnmod\\t_\\tSpaceAfter=No\\n20\\t,\\t,\\tPUNCT\\tFF\\t_\\t21\\tpunct\\t_\\t_\\n21\\tSweden\\tSweden\\tPROPN\\tSP\\t_\\t19\\tconj\\t_\\t_\\n22\\tand\\tand\\tCCONJ\\tCC\\t_\\t23\\tcc\\t_\\t_\\n23\\tJapan\\tJapan\\tPROPN\\tSP\\t_\\t19\\tconj\\t_\\tSpaceAfter=No\\n24\\t)\\t)\\tPUNCT\\tFB\\t_\\t19\\tpunct\\t_\\t_\\n25\\tin\\tin\\tADP\\tE\\t_\\t28\\tcase\\t_\\t_\\n26\\tthe\\tthe\\tDET\\tRD\\tDefinite=Def|PronType=Art\\t28\\tdet\\t_\\t_\\n27\\tsecond\\tsecond\\tADJ\\tNO\\tDegree=Pos|NumType=Ord\\t28\\tamod\\t_\\t_\\n28\\thalf\\thalf\\tNOUN\\tS\\tNumber=Sing\\t17\\tnmod\\t_\\t_\\n29\\tof\\tof\\tADP\\tE\\t_\\t33\\tcase\\t_\\t_\\n30\\tthe\\tthe\\tDET\\tRD\\tDefinite=Def|PronType=Art\\t33\\tdet\\t_\\t_\\n31\\t20\\t20\\tNUM\\tN\\tNumType=Card\\t33\\tnummod\\t_\\tSpaceAfter=No\\n32\\tTh\\tth\\tADJ\\tA\\tDegree=Pos\\t31\\tgoeswith\\t_\\t_\\n33\\tcentury\\tcentury\\tNOUN\\tS\\tNumber=Sing\\t28\\tnmod\\t_\\t_\\n34\\tand\\tand\\tCCONJ\\tCC\\t_\\t37\\tcc\\t_\\t_\\n35\\tup\\tup\\tADV\\tB\\t_\\t37\\tadvmod\\t_\\t_\\n36\\tto\\tto\\tADP\\tE\\t_\\t37\\tcase\\t_\\t_\\n37\\t2040\\t2040\\tNUM\\tN\\tNumType=Card\\t28\\tconj\\t_\\tSpaceAfter=No\\n38\\t.\\t.\\tPUNCT\\tFS\\t_\\t4\\tpunct\\t_\\t_\\n\\n# sent_id = 2\\n# text = But what factory make the figures so varied?\\n1\\tBut\\tbut\\tCCONJ\\tCC\\t_\\t4\\tcc\\t_\\t_\\n2\\twhat\\twhat\\tDET\\tDQ\\tPronType=Int\\t3\\tdet\\t_\\t_\\n3\\tfactory\\tfactory\\tNOUN\\tS\\tNumber=Sing\\t4\\tnsubj\\t_\\t_\\n4\\tmake\\tmake\\tVERB\\tV\\tMood=Ind|Number=Plur|Tense=Pres|VerbForm=Fin\\t0\\troot\\t_\\t_\\n5\\tthe\\tthe\\tDET\\tRD\\tDefinite=Def|PronType=Art\\t6\\tdet\\t_\\t_\\n6\\tfigures\\tfigure\\tNOUN\\tS\\tNumber=Plur\\t4\\tobj\\t_\\t_\\n7\\tso\\tso\\tADV\\tB\\t_\\t8\\tadvmod\\t_\\t_\\n8\\tvaried\\tvary\\tVERB\\tV\\tTense=Past|VerbForm=Part\\t4\\txcomp\\t_\\tSpaceAfter=No\\n9\\t?\\t?\\tPUNCT\\tFS\\t_\\t4\\tpunct\\t_\\tSpacesAfter=\\\\s\\\\n\\n\\n# sent_id = 3\\n# text = First of all, it is the average length of life.\\n1\\tFirst\\tfirst\\tADJ\\tNO\\tDegree=Pos|NumType=Ord\\t9\\tamod\\t_\\t_\\n2\\tof\\tof\\tADP\\tE\\t_\\t3\\tcase\\t_\\t_\\n3\\tall\\tall\\tPRON\\tPI\\tPronType=Ind\\t1\\tobl\\t_\\tSpaceAfter=No\\n4\\t,\\t,\\tPUNCT\\tFF\\t_\\t1\\tpunct\\t_\\t_\\n5\\tit\\tit\\tPRON\\tPE\\tNumber=Sing|Person=3|PronType=Prs\\t9\\tnsubj\\t_\\t_\\n6\\tis\\tbe\\tAUX\\tVA\\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\\t9\\tcop\\t_\\t_\\n7\\tthe\\tthe\\tDET\\tRD\\tDefinite=Def|PronType=Art\\t9\\tdet\\t_\\t_\\n8\\taverage\\taverage\\tADJ\\tA\\tDegree=Pos\\t9\\tamod\\t_\\t_\\n9\\tlength\\tlength\\tNOUN\\tS\\tNumber=Sing\\t0\\troot\\t_\\t_\\n10\\tof\\tof\\tADP\\tE\\t_\\t11\\tcase\\t_\\t_\\n11\\tlife\\tlife\\tNOUN\\tS\\tNumber=Sing\\t9\\tnmod\\t_\\tSpaceAfter=No\\n12\\t.\\t.\\tPUNCT\\tFS\\t_\\t9\\tpunct\\t_\\t_\\n\\n# sent_id = 4\\n# text = Japan is well-known for its long-living people , and that is why the proportion of them is expected to ex cud 25% by 2040.\\n1\\tJapan\\tJapan\\tPROPN\\tSP\\t_\\t5\\tnsubj\\t_\\t_\\n2\\tis\\tbe\\tAUX\\tVA\\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\\t5\\tcop\\t_\\t_\\n3\\twell\\twell\\tADV\\tB\\t_\\t5\\tadvmod\\t_\\tSpaceAfter=No\\n4\\t-\\t-\\tPUNCT\\tFF\\t_\\t3\\tpunct\\t_\\tSpaceAfter=No\\n5\\tknown\\tknow\\tADJ\\tA\\tDegree=Pos\\t0\\troot\\t_\\t_\\n6\\tfor\\tfor\\tADP\\tE\\t_\\t11\\tcase\\t_\\t_\\n7\\tits\\tits\\tDET\\tAP\\tNumber=Sing|Poss=Yes|PronType=Prs\\t11\\tnmod:poss\\t_\\t_\\n8\\tlong\\tlong\\tADV\\tB\\t_\\t10\\tadvmod\\t_\\tSpaceAfter=No\\n9\\t-\\t-\\tPUNCT\\tFF\\t_\\t8\\tpunct\\t_\\tSpaceAfter=No\\n10\\tliving\\tlive\\tVERB\\tV\\tNumber=Sing|Tense=Pres|VerbForm=Part\\t11\\tacl\\t_\\t_\\n11\\tpeople\\tpeople\\tNOUN\\tS\\tNumber=Plur\\t5\\tobl\\t_\\t_\\n12\\t,\\t,\\tPUNCT\\tFF\\t_\\t5\\tpunct\\t_\\t_\\n13\\tand\\tand\\tCCONJ\\tCC\\t_\\t18\\tcc\\t_\\t_\\n14\\tthat\\tthat\\tPRON\\tPD\\tPronType=Dem\\t18\\tnsubj\\t_\\t_\\n15\\tis\\tbe\\tAUX\\tVA\\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\\t18\\tcop\\t_\\t_\\n16\\twhy\\twhy\\tADV\\tB\\t_\\t18\\tadvmod\\t_\\t_\\n17\\tthe\\tthe\\tDET\\tRD\\tDefinite=Def|PronType=Art\\t18\\tdet\\t_\\t_\\n18\\tproportion\\tproportion\\tNOUN\\tS\\tNumber=Sing\\t22\\tnsubj:pass\\t_\\t_\\n19\\tof\\tof\\tADP\\tE\\t_\\t20\\tcase\\t_\\t_\\n20\\tthem\\tthey\\tPRON\\tPE\\tNumber=Plur|Person=3|PronType=Prs\\t18\\tnmod\\t_\\t_\\n21\\tis\\tbe\\tAUX\\tVA\\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\\t22\\taux:pass\\t_\\t_\\n22\\texpected\\texpect\\tVERB\\tV\\tTense=Past|VerbForm=Part\\t5\\tadvcl\\t_\\t_\\n23\\tto\\tto\\tADP\\tE\\t_\\t25\\tcase\\t_\\t_\\n24\\tex\\tex\\tNUM\\tN\\tNumType=Card\\t25\\tnummod\\t_\\t_\\n25\\tcud\\tcu\\tNOUN\\tS\\tNumber=Sing\\t22\\tobl\\t_\\t_\\n26\\t25\\t25\\tNUM\\tN\\tNumType=Card\\t27\\tnummod\\t_\\tSpaceAfter=No\\n27\\t%\\t%\\tSYM\\tX\\t_\\t25\\tnmod\\t_\\t_\\n28\\tby\\tby\\tADP\\tE\\t_\\t29\\tcase\\t_\\t_\\n29\\t2040\\t2040\\tNUM\\tN\\tNumType=Card\\t22\\tobl:agent\\t_\\tSpaceAfter=No\\n30\\t.\\t.\\tPUNCT\\tFS\\t_\\t5\\tpunct\\t_\\t_\\n\\n# sent_id = 5\\n# text = However, the economic situation has not always been so brilliant , moreover, it was much worse there then in Europe and America , so the number was relatively low until the expected acute rise in 2030.\\n1\\tHowever\\thowever\\tADV\\tB\\t_\\t11\\tadvmod\\t_\\tSpaceAfter=No\\n2\\t,\\t,\\tPUNCT\\tFF\\t_\\t1\\tpunct\\t_\\t_\\n3\\tthe\\tthe\\tDET\\tRD\\tDefinite=Def|PronType=Art\\t5\\tdet\\t_\\t_\\n4\\teconomic\\teconomic\\tADJ\\tA\\tDegree=Pos\\t5\\tamod\\t_\\t_\\n5\\tsituation\\tsituation\\tNOUN\\tS\\tNumber=Sing\\t11\\tnsubj\\t_\\t_\\n6\\thas\\thave\\tAUX\\tVA\\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\\t11\\taux\\t_\\t_\\n7\\tnot\\tnot\\tPART\\tPART\\tPolarity=Neg\\t8\\tadvmod\\t_\\t_\\n8\\talways\\talways\\tADV\\tB\\t_\\t11\\tadvmod\\t_\\t_\\n9\\tbeen\\tbe\\tAUX\\tVA\\tTense=Past|VerbForm=Part\\t11\\tcop\\t_\\t_\\n10\\tso\\tso\\tADV\\tB\\t_\\t11\\tadvmod\\t_\\t_\\n11\\tbrilliant\\tbrilliant\\tADJ\\tA\\tDegree=Pos\\t18\\tadvcl\\t_\\t_\\n12\\t,\\t,\\tPUNCT\\tFF\\t_\\t13\\tpunct\\t_\\t_\\n13\\tmoreover\\tmoreover\\tNOUN\\tS\\tNumber=Sing\\t11\\tconj\\t_\\tSpaceAfter=No\\n14\\t,\\t,\\tPUNCT\\tFF\\t_\\t11\\tpunct\\t_\\t_\\n15\\tit\\tit\\tPRON\\tPE\\tNumber=Sing|Person=3|PronType=Prs\\t18\\tnsubj\\t_\\t_\\n16\\twas\\tbe\\tAUX\\tVA\\tMood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\\t18\\taux\\t_\\t_\\n17\\tmuch\\tmuch\\tADV\\tB\\t_\\t18\\tadvmod\\t_\\t_\\n18\\tworse\\tworse\\tVERB\\tV\\tMood=Ind|Number=Plur|Tense=Pres|VerbForm=Fin\\t0\\troot\\t_\\t_\\n19\\tthere\\tthere\\tADV\\tB\\t_\\t20\\tadvmod\\t_\\t_\\n20\\tthen\\tthen\\tADV\\tB\\t_\\t18\\tadvmod\\t_\\t_\\n21\\tin\\tin\\tADP\\tE\\t_\\t22\\tcase\\t_\\t_\\n22\\tEurope\\tEurope\\tPROPN\\tSP\\t_\\t18\\tobl\\t_\\t_\\n23\\tand\\tand\\tCCONJ\\tCC\\t_\\t24\\tcc\\t_\\t_\\n24\\tAmerica\\tAmerica\\tPROPN\\tSP\\t_\\t22\\tconj\\t_\\t_\\n25\\t,\\t,\\tPUNCT\\tFF\\t_\\t31\\tpunct\\t_\\t_\\n26\\tso\\tso\\tADV\\tB\\t_\\t31\\tadvmod\\t_\\t_\\n27\\tthe\\tthe\\tDET\\tRD\\tDefinite=Def|PronType=Art\\t28\\tdet\\t_\\t_\\n28\\tnumber\\tnumber\\tNOUN\\tS\\tNumber=Sing\\t31\\tnsubj\\t_\\t_\\n29\\twas\\tbe\\tAUX\\tVA\\tMood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\\t31\\tcop\\t_\\t_\\n30\\trelatively\\trelatively\\tADV\\tB\\t_\\t31\\tadvmod\\t_\\t_\\n31\\tlow\\tlow\\tADJ\\tA\\tDegree=Pos\\t18\\tconj\\t_\\t_\\n32\\tuntil\\tuntil\\tSCONJ\\tCS\\t_\\t36\\tcase\\t_\\t_\\n33\\tthe\\tthe\\tDET\\tRD\\tDefinite=Def|PronType=Art\\t36\\tdet\\t_\\t_\\n34\\texpected\\texpect\\tADJ\\tA\\tDegree=Pos\\t36\\tamod\\t_\\t_\\n35\\tacute\\tacute\\tNOUN\\tS\\tNumber=Sing\\t36\\tnmod\\t_\\t_\\n36\\trise\\trise\\tNOUN\\tS\\tNumber=Sing\\t31\\tobl\\t_\\t_\\n37\\tin\\tin\\tADP\\tE\\t_\\t38\\tcase\\t_\\t_\\n38\\t2030\\t2030\\tNUM\\tN\\tNumType=Card\\t36\\tnummod\\t_\\tSpaceAfter=No\\n39\\t.\\t.\\tPUNCT\\tFS\\t_\\t18\\tpunct\\t_\\t_\\n\\n# sent_id = 6\\n# text = Also, that is due to the fact that more children are born in Japan , and as a result, they take up some 'space' in the generations division.\\n1\\tAlso\\talso\\tADV\\tB\\t_\\t5\\tadvmod\\t_\\tSpaceAfter=No\\n2\\t,\\t,\\tPUNCT\\tFF\\t_\\t1\\tpunct\\t_\\t_\\n3\\tthat\\tthat\\tPRON\\tPD\\tPronType=Dem\\t5\\tnsubj\\t_\\t_\\n4\\tis\\tbe\\tAUX\\tVA\\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\\t5\\tcop\\t_\\t_\\n5\\tdue\\tdue\\tADJ\\tA\\tDegree=Pos\\t0\\troot\\t_\\t_\\n6\\tto\\tto\\tADP\\tE\\t_\\t8\\tcase\\t_\\t_\\n7\\tthe\\tthe\\tDET\\tRD\\tDefinite=Def|PronType=Art\\t8\\tdet\\t_\\t_\\n8\\tfact\\tfact\\tNOUN\\tS\\tNumber=Sing\\t5\\tobl\\t_\\t_\\n9\\tthat\\tthat\\tSCONJ\\tCS\\t_\\t13\\tmark\\t_\\t_\\n10\\tmore\\tmore\\tADV\\tB\\tDegree=Cmp\\t13\\tadvmod\\t_\\t_\\n11\\tchildren\\tchild\\tNOUN\\tS\\tGender=Masc|Number=Plur\\t13\\tnsubj:pass\\t_\\t_\\n12\\tare\\tbe\\tAUX\\tVA\\tMood=Ind|Number=Plur|Tense=Pres|VerbForm=Fin\\t13\\taux:pass\\t_\\t_\\n13\\tborn\\tbear\\tVERB\\tV\\tTense=Past|VerbForm=Part\\t8\\tacl\\t_\\t_\\n14\\tin\\tin\\tADP\\tE\\t_\\t15\\tcase\\t_\\t_\\n15\\tJapan\\tJapan\\tPROPN\\tSP\\t_\\t13\\tobl\\t_\\t_\\n16\\t,\\t,\\tPUNCT\\tFF\\t_\\t23\\tpunct\\t_\\t_\\n17\\tand\\tand\\tCCONJ\\tCC\\t_\\t23\\tcc\\t_\\t_\\n18\\tas\\tas\\tADP\\tE\\t_\\t20\\tcase\\t_\\t_\\n19\\ta\\ta\\tDET\\tRI\\tDefinite=Ind|Number=Sing|PronType=Art\\t20\\tdet\\t_\\t_\\n20\\tresult\\tresult\\tNOUN\\tS\\tNumber=Sing\\t23\\tobl\\t_\\tSpaceAfter=No\\n21\\t,\\t,\\tPUNCT\\tFF\\t_\\t20\\tpunct\\t_\\t_\\n22\\tthey\\tthey\\tPRON\\tPE\\tNumber=Plur|Person=3|PronType=Prs\\t23\\tnsubj\\t_\\t_\\n23\\ttake\\ttake\\tVERB\\tV\\tMood=Ind|Number=Plur|Tense=Pres|VerbForm=Fin\\t8\\tconj\\t_\\t_\\n24\\tup\\tup\\tADP\\tE\\t_\\t23\\tcompound:prt\\t_\\t_\\n25\\tsome\\tsome\\tDET\\tDI\\tPronType=Ind\\t27\\tdet\\t_\\t_\\n26\\t'\\t'\\tX\\tX\\t_\\t27\\tnmod\\t_\\tSpaceAfter=No\\n27\\tspace\\tspace\\tNOUN\\tS\\tNumber=Sing\\t23\\tobj\\t_\\tSpaceAfter=No\\n28\\t'\\t'\\tX\\tX\\t_\\t27\\tgoeswith\\t_\\t_\\n29\\tin\\tin\\tADP\\tE\\t_\\t32\\tcase\\t_\\t_\\n30\\tthe\\tthe\\tDET\\tRD\\tDefinite=Def|PronType=Art\\t32\\tdet\\t_\\t_\\n31\\tgenerations\\tgeneration\\tNOUN\\tS\\tNumber=Plur\\t32\\tnmod\\t_\\t_\\n32\\tdivision\\tdivision\\tNOUN\\tS\\tNumber=Sing\\t23\\tobl\\t_\\tSpaceAfter=No\\n33\\t.\\t.\\tPUNCT\\tFS\\t_\\t5\\tpunct\\t_\\tSpacesAfter=\\\\s\\\\n\\n\\n# sent_id = 7\\n# text = Secondly, it is social policy that affects the quality of life.\\n1\\tSecondly\\tsecondly\\tADV\\tB\\t_\\t6\\tadvmod\\t_\\tSpaceAfter=No\\n2\\t,\\t,\\tPUNCT\\tFF\\t_\\t1\\tpunct\\t_\\t_\\n3\\tit\\tit\\tPRON\\tPE\\tNumber=Sing|Person=3|PronType=Prs\\t6\\tnsubj\\t_\\t_\\n4\\tis\\tbe\\tAUX\\tVA\\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\\t6\\tcop\\t_\\t_\\n5\\tsocial\\tsocial\\tADJ\\tA\\tDegree=Pos\\t6\\tamod\\t_\\t_\\n6\\tpolicy\\tpolicy\\tNOUN\\tS\\tNumber=Sing\\t0\\troot\\t_\\t_\\n7\\tthat\\tthat\\tPRON\\tPR\\tPronType=Rel\\t8\\tnsubj\\t_\\t_\\n8\\taffects\\taffect\\tVERB\\tV\\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\\t6\\tacl:relcl\\t_\\t_\\n9\\tthe\\tthe\\tDET\\tRD\\tDefinite=Def|PronType=Art\\t10\\tdet\\t_\\t_\\n10\\tquality\\tquality\\tNOUN\\tS\\tNumber=Sing\\t8\\tobj\\t_\\t_\\n11\\tof\\tof\\tADP\\tE\\t_\\t12\\tcase\\t_\\t_\\n12\\tlife\\tlife\\tNOUN\\tS\\tNumber=Sing\\t10\\tnmod\\t_\\tSpaceAfter=No\\n13\\t.\\t.\\tPUNCT\\tFS\\t_\\t6\\tpunct\\t_\\t_\\n\\n# sent_id = 8\\n# text = After the introduction of state insurance and pensions both in the USA and Sweden , more elderly people were able to afford suitable medical treatment, housing or other benefits.\\n1\\tAfter\\tafter\\tADP\\tE\\t_\\t3\\tcase\\t_\\t_\\n2\\tthe\\tthe\\tDET\\tRD\\tDefinite=Def|PronType=Art\\t3\\tdet\\t_\\t_\\n3\\tintroduction\\tintroduction\\tNOUN\\tS\\tNumber=Sing\\t20\\tobl\\t_\\t_\\n4\\tof\\tof\\tADP\\tE\\t_\\t6\\tcase\\t_\\t_\\n5\\tstate\\tstate\\tNOUN\\tS\\tNumber=Sing\\t6\\tnmod\\t_\\t_\\n6\\tinsurance\\tinsurance\\tNOUN\\tS\\tNumber=Sing\\t3\\tnmod\\t_\\t_\\n7\\tand\\tand\\tCCONJ\\tCC\\t_\\t8\\tcc\\t_\\t_\\n8\\tpensions\\tpension\\tNOUN\\tS\\tNumber=Plur\\t6\\tconj\\t_\\t_\\n9\\tboth\\tboth\\tCCONJ\\tCC\\t_\\t12\\tcc\\t_\\t_\\n10\\tin\\tin\\tADP\\tE\\t_\\t12\\tcase\\t_\\t_\\n11\\tthe\\tthe\\tDET\\tRD\\tDefinite=Def|PronType=Art\\t12\\tdet\\t_\\t_\\n12\\tUSA\\tUSA\\tPROPN\\tSP\\t_\\t3\\tconj\\t_\\t_\\n13\\tand\\tand\\tCCONJ\\tCC\\t_\\t14\\tcc\\t_\\t_\\n14\\tSweden\\tSweden\\tPROPN\\tSP\\t_\\t12\\tconj\\t_\\t_\\n15\\t,\\t,\\tPUNCT\\tFF\\t_\\t3\\tpunct\\t_\\t_\\n16\\tmore\\tmore\\tADV\\tB\\tDegree=Cmp\\t17\\tadvmod\\t_\\t_\\n17\\telderly\\telderly\\tADJ\\tA\\tDegree=Pos\\t18\\tamod\\t_\\t_\\n18\\tpeople\\tpeople\\tNOUN\\tS\\tNumber=Plur\\t20\\tnsubj\\t_\\t_\\n19\\twere\\tbe\\tAUX\\tVA\\tMood=Ind|Number=Plur|Tense=Past|VerbForm=Fin\\t20\\tcop\\t_\\t_\\n20\\table\\table\\tADJ\\tA\\tDegree=Pos\\t0\\troot\\t_\\t_\\n21\\tto\\tto\\tPART\\tPART\\t_\\t22\\tmark\\t_\\t_\\n22\\tafford\\tafford\\tVERB\\tV\\tVerbForm=Inf\\t20\\txcomp\\t_\\t_\\n23\\tsuitable\\tsuitable\\tADJ\\tA\\tDegree=Pos\\t25\\tamod\\t_\\t_\\n24\\tmedical\\tmedical\\tADJ\\tA\\tDegree=Pos\\t25\\tamod\\t_\\t_\\n25\\ttreatment\\ttreatment\\tNOUN\\tS\\tNumber=Sing\\t22\\tobj\\t_\\tSpaceAfter=No\\n26\\t,\\t,\\tPUNCT\\tFF\\t_\\t27\\tpunct\\t_\\t_\\n27\\thousing\\thousing\\tNOUN\\tS\\tNumber=Sing\\t25\\tconj\\t_\\t_\\n28\\tor\\tor\\tCCONJ\\tCC\\t_\\t30\\tcc\\t_\\t_\\n29\\tother\\tother\\tADJ\\tA\\tDegree=Pos\\t30\\tamod\\t_\\t_\\n30\\tbenefits\\tbenefit\\tNOUN\\tS\\tNumber=Plur\\t25\\tconj\\t_\\tSpaceAfter=No\\n31\\t.\\t.\\tPUNCT\\tFS\\t_\\t20\\tpunct\\t_\\t_\\n\\n# sent_id = 9\\n# text = Another option is the decline in the number of children per family.\\n1\\tAnother\\tanother\\tDET\\tRI\\tDefinite=Ind|Number=Sing|PronType=Art\\t2\\tdet\\t_\\t_\\n2\\toption\\toption\\tNOUN\\tS\\tNumber=Sing\\t5\\tnsubj\\t_\\t_\\n3\\tis\\tbe\\tAUX\\tVA\\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\\t5\\tcop\\t_\\t_\\n4\\tthe\\tthe\\tDET\\tRD\\tDefinite=Def|PronType=Art\\t5\\tdet\\t_\\t_\\n5\\tdecline\\tdecline\\tNOUN\\tS\\tNumber=Sing\\t0\\troot\\t_\\t_\\n6\\tin\\tin\\tADP\\tE\\t_\\t8\\tcase\\t_\\t_\\n7\\tthe\\tthe\\tDET\\tRD\\tDefinite=Def|PronType=Art\\t8\\tdet\\t_\\t_\\n8\\tnumber\\tnumber\\tNOUN\\tS\\tNumber=Sing\\t5\\tnmod\\t_\\t_\\n9\\tof\\tof\\tADP\\tE\\t_\\t10\\tcase\\t_\\t_\\n10\\tchildren\\tchild\\tNOUN\\tS\\tGender=Masc|Number=Plur\\t8\\tnmod\\t_\\t_\\n11\\tper\\tper\\tADP\\tE\\t_\\t12\\tcase\\t_\\t_\\n12\\tfamily\\tfamily\\tNOUN\\tS\\tNumber=Sing\\t10\\tnmod\\t_\\tSpaceAfter=No\\n13\\t.\\t.\\tPUNCT\\tFS\\t_\\t5\\tpunct\\t_\\t_\\n\\n# sent_id = 10\\n# text = More and more young people decline to start a family later an have only 1 or 2 offspring , and this tendency will certainly bring about the growth of the proportion of the elderly people, as those born in 1975 are 65 years old by 2040.\\n1\\tMore\\tmore\\tADV\\tB\\t_\\t13\\tadvmod\\t_\\t_\\n2\\tand\\tand\\tCCONJ\\tCC\\t_\\t6\\tcc\\t_\\t_\\n3\\tmore\\tmore\\tADV\\tB\\tDegree=Cmp\\t4\\tadvmod\\t_\\t_\\n4\\tyoung\\tyoung\\tADJ\\tA\\tDegree=Pos\\t6\\tamod\\t_\\t_\\n5\\tpeople\\tpeople\\tNOUN\\tS\\tNumber=Plur\\t6\\tnmod\\t_\\t_\\n6\\tdecline\\tdecline\\tNOUN\\tS\\tNumber=Sing\\t13\\tnsubj\\t_\\t_\\n7\\tto\\tto\\tPART\\tPART\\t_\\t8\\tmark\\t_\\t_\\n8\\tstart\\tstart\\tVERB\\tV\\tVerbForm=Inf\\t13\\tcsubj\\t_\\t_\\n9\\ta\\ta\\tDET\\tRI\\tDefinite=Ind|Number=Sing|PronType=Art\\t10\\tdet\\t_\\t_\\n10\\tfamily\\tfamily\\tNOUN\\tS\\tNumber=Sing\\t8\\tobj\\t_\\t_\\n11\\tlater\\tlater\\tADV\\tB\\tDegree=Cmp\\t13\\tadvmod\\t_\\t_\\n12\\tan\\ta\\tDET\\tRI\\tDefinite=Ind|Number=Sing|PronType=Art\\t13\\tdet\\t_\\t_\\n13\\thave\\thave\\tVERB\\tV\\tMood=Ind|Number=Plur|Tense=Pres|VerbForm=Fin\\t0\\troot\\t_\\t_\\n14\\tonly\\tonly\\tADV\\tB\\t_\\t18\\tadvmod\\t_\\t_\\n15\\t1\\t1\\tNUM\\tN\\tNumType=Card\\t18\\tnummod\\t_\\t_\\n16\\tor\\tor\\tCCONJ\\tCC\\t_\\t17\\tcc\\t_\\t_\\n17\\t2\\t2\\tNUM\\tN\\tNumType=Card\\t15\\tconj\\t_\\t_\\n18\\toffspring\\toffspring\\tNOUN\\tS\\tNumber=Sing\\t13\\tobj\\t_\\t_\\n19\\t,\\t,\\tPUNCT\\tFF\\t_\\t25\\tpunct\\t_\\t_\\n20\\tand\\tand\\tCCONJ\\tCC\\t_\\t25\\tcc\\t_\\t_\\n21\\tthis\\tthis\\tDET\\tDD\\tNumber=Sing|PronType=Dem\\t22\\tdet\\t_\\t_\\n22\\ttendency\\ttendency\\tNOUN\\tS\\tNumber=Sing\\t25\\tnsubj\\t_\\t_\\n23\\twill\\twill\\tAUX\\tVM\\tMood=Ind|Person=3|Tense=Pres|VerbForm=Fin\\t25\\taux\\t_\\t_\\n24\\tcertainly\\tcertainly\\tADV\\tB\\t_\\t25\\tadvmod\\t_\\t_\\n25\\tbring\\tbring\\tVERB\\tV\\tVerbForm=Inf\\t13\\tconj\\t_\\t_\\n26\\tabout\\tabout\\tADP\\tE\\t_\\t28\\tcase\\t_\\t_\\n27\\tthe\\tthe\\tDET\\tRD\\tDefinite=Def|PronType=Art\\t28\\tdet\\t_\\t_\\n28\\tgrowth\\tgrowth\\tNOUN\\tS\\tNumber=Sing\\t25\\tobl\\t_\\t_\\n29\\tof\\tof\\tADP\\tE\\t_\\t31\\tcase\\t_\\t_\\n30\\tthe\\tthe\\tDET\\tRD\\tDefinite=Def|PronType=Art\\t31\\tdet\\t_\\t_\\n31\\tproportion\\tproportion\\tNOUN\\tS\\tNumber=Sing\\t28\\tnmod\\t_\\t_\\n32\\tof\\tof\\tADP\\tE\\t_\\t35\\tcase\\t_\\t_\\n33\\tthe\\tthe\\tDET\\tRD\\tDefinite=Def|PronType=Art\\t35\\tdet\\t_\\t_\\n34\\telderly\\telderly\\tADJ\\tA\\tDegree=Pos\\t35\\tamod\\t_\\t_\\n35\\tpeople\\tpeople\\tNOUN\\tS\\tNumber=Plur\\t31\\tnmod\\t_\\tSpaceAfter=No\\n36\\t,\\t,\\tPUNCT\\tFF\\t_\\t25\\tpunct\\t_\\t_\\n37\\tas\\tas\\tADP\\tE\\t_\\t38\\tcase\\t_\\t_\\n38\\tthose\\tthat\\tPRON\\tPD\\tNumber=Plur|PronType=Dem\\t25\\tobl\\t_\\t_\\n39\\tborn\\tborn\\tVERB\\tV\\tMood=Ind|Number=Plur|Tense=Pres|VerbForm=Fin\\t38\\tacl\\t_\\t_\\n40\\tin\\tin\\tADP\\tE\\t_\\t41\\tcase\\t_\\t_\\n41\\t1975\\t1975\\tNUM\\tN\\tNumType=Card\\t39\\tobl\\t_\\t_\\n42\\tare\\tbe\\tAUX\\tVA\\tMood=Ind|Number=Plur|Tense=Pres|VerbForm=Fin\\t45\\tcop\\t_\\t_\\n43\\t65\\t65\\tNUM\\tN\\tNumType=Card\\t44\\tnummod\\t_\\t_\\n44\\tyears\\tyear\\tNOUN\\tS\\tNumber=Plur\\t45\\tobl\\t_\\t_\\n45\\told\\told\\tADJ\\tA\\tDegree=Pos\\t38\\tamod\\t_\\t_\\n46\\tby\\tby\\tADP\\tE\\t_\\t47\\tcase\\t_\\t_\\n47\\t2040\\t2040\\tNUM\\tN\\tNumType=Card\\t45\\tobl\\t_\\tSpaceAfter=No\\n48\\t.\\t.\\tPUNCT\\tFS\\t_\\t13\\tpunct\\t_\\tSpacesAfter=\\\\n\\n\\n# sent_id = 11\\n# text = To draw a conclusion, we may say that not only social or economic tendencies , but also government policies might cause certain changes in social proportions , consequently, these policies and tendencies should be accurately governed.\\n1\\tTo\\tto\\tADP\\tE\\t_\\t2\\tmark\\t_\\t_\\n2\\tdraw\\tdraw\\tVERB\\tV\\tVerbForm=Inf\\t8\\tadvcl\\t_\\t_\\n3\\ta\\ta\\tDET\\tRI\\tDefinite=Ind|Number=Sing|PronType=Art\\t4\\tdet\\t_\\t_\\n4\\tconclusion\\tconclusion\\tNOUN\\tS\\tNumber=Sing\\t2\\tobj\\t_\\tSpaceAfter=No\\n5\\t,\\t,\\tPUNCT\\tFF\\t_\\t2\\tpunct\\t_\\t_\\n6\\twe\\twe\\tPRON\\tPE\\tNumber=Plur|Person=1|PronType=Prs\\t8\\tnsubj\\t_\\t_\\n7\\tmay\\tmay\\tAUX\\tVM\\tMood=Ind|Person=3|Tense=Pres|VerbForm=Fin\\t8\\taux\\t_\\t_\\n8\\tsay\\tsay\\tVERB\\tV\\tVerbForm=Inf\\t0\\troot\\t_\\t_\\n9\\tthat\\tthat\\tSCONJ\\tCS\\t_\\t22\\tmark\\t_\\t_\\n10\\tnot\\tnot\\tPART\\tPART\\tPolarity=Neg\\t15\\tadvmod\\t_\\t_\\n11\\tonly\\tonly\\tADV\\tB\\t_\\t12\\tadvmod\\t_\\t_\\n12\\tsocial\\tsocial\\tADJ\\tA\\tDegree=Pos\\t15\\tamod\\t_\\t_\\n13\\tor\\tor\\tCCONJ\\tCC\\t_\\t14\\tcc\\t_\\t_\\n14\\teconomic\\teconomic\\tADJ\\tA\\tDegree=Pos\\t12\\tconj\\t_\\t_\\n15\\ttendencies\\ttendency\\tNOUN\\tS\\tNumber=Plur\\t22\\tnsubj\\t_\\t_\\n16\\t,\\t,\\tPUNCT\\tFF\\t_\\t20\\tpunct\\t_\\t_\\n17\\tbut\\tbut\\tCCONJ\\tCC\\t_\\t20\\tcc\\t_\\t_\\n18\\talso\\talso\\tADV\\tB\\t_\\t20\\tadvmod\\t_\\t_\\n19\\tgovernment\\tgovernment\\tNOUN\\tS\\tNumber=Sing\\t20\\tnmod\\t_\\t_\\n20\\tpolicies\\tpolicy\\tNOUN\\tS\\tNumber=Plur\\t15\\tconj\\t_\\t_\\n21\\tmight\\tmay\\tAUX\\tVM\\tMood=Ind|Person=3|Tense=Past|VerbForm=Fin\\t22\\taux\\t_\\t_\\n22\\tcause\\tcause\\tVERB\\tV\\tVerbForm=Inf\\t8\\tccomp\\t_\\t_\\n23\\tcertain\\tcertain\\tADJ\\tA\\tDegree=Pos\\t24\\tamod\\t_\\t_\\n24\\tchanges\\tchange\\tNOUN\\tS\\tNumber=Plur\\t22\\tobj\\t_\\t_\\n25\\tin\\tin\\tADP\\tE\\t_\\t27\\tcase\\t_\\t_\\n26\\tsocial\\tsocial\\tADJ\\tA\\tDegree=Pos\\t27\\tamod\\t_\\t_\\n27\\tproportions\\tproportion\\tNOUN\\tS\\tNumber=Plur\\t22\\tobl\\t_\\t_\\n28\\t,\\t,\\tPUNCT\\tFF\\t_\\t22\\tpunct\\t_\\t_\\n29\\tconsequently\\tconsequently\\tADV\\tB\\t_\\t22\\tadvmod\\t_\\tSpaceAfter=No\\n30\\t,\\t,\\tPUNCT\\tFF\\t_\\t22\\tpunct\\t_\\t_\\n31\\tthese\\tthis\\tDET\\tDD\\tNumber=Plur|PronType=Dem\\t32\\tdet\\t_\\t_\\n32\\tpolicies\\tpolicy\\tNOUN\\tS\\tNumber=Plur\\t22\\tobj\\t_\\t_\\n33\\tand\\tand\\tCCONJ\\tCC\\t_\\t38\\tcc\\t_\\t_\\n34\\ttendencies\\ttendency\\tNOUN\\tS\\tNumber=Plur\\t38\\tnsubj:pass\\t_\\t_\\n35\\tshould\\tshall\\tAUX\\tVM\\tMood=Ind|Person=3|Tense=Past|VerbForm=Fin\\t38\\taux\\t_\\t_\\n36\\tbe\\tbe\\tAUX\\tVA\\tVerbForm=Inf\\t38\\taux:pass\\t_\\t_\\n37\\taccurately\\taccurately\\tADV\\tB\\t_\\t38\\tadvmod\\t_\\t_\\n38\\tgoverned\\tgoverned\\tVERB\\tV\\tTense=Past|VerbForm=Part\\t32\\tconj\\t_\\tSpaceAfter=No\\n39\\t.\\t.\\tPUNCT\\tFS\\t_\\t8\\tpunct\\t_\\tSpacesAfter=\\\\s\\\\n\\n\\n\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
