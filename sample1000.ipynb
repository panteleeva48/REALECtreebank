{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from syn_compl import (get_parsed_text, count_tokens, \n",
    "av_depth_for_one_text, min_depth_for_one_text, \n",
    "max_depth_for_one_text, count_acl, count_acl_relcl,\n",
    "count_advcl, count_sent, count_clauses, count_tunits,\n",
    "count_complex_tunit, count_coord, count_np, count_vp,\n",
    "lemma_sim_mean, pos_sim_mean, tokens_befor_root, mean_len_sent,\n",
    "find_inf, pos_sim_mean2, lemma_sim_mean2)\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_hole_file(name_file):\n",
    "    f = open(name_file, 'r')\n",
    "    f_r = f.read()\n",
    "    return f_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "esse_gr_lst = read_hole_file('/Users/irene/Desktop/Курсовая/1_1000sample.csv').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gr(grade):\n",
    "    if int(grade) < 50:\n",
    "        res = 'worst'\n",
    "    elif int(grade) >= 70:\n",
    "        res = 'best'\n",
    "    else:\n",
    "        res = 'aver'\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "string = ''\n",
    "string2 = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/irene/Downloads/exam/exam2014/ASt_17_1.txt\n",
      "/Users/irene/Downloads/exam/exam2014/KKo_2_1.txt\n",
      "/Users/irene/Downloads/exam/exam2014/MTsy_1_1.txt\n",
      "/Users/irene/Downloads/exam/exam2014/MTsy_27_1.txt\n",
      "/Users/irene/Downloads/exam/exam2014/MTsy_35_1.txt\n",
      "/Users/irene/Downloads/old IELTS/IELTS2015/KKo_10_1.txt\n",
      "/Users/irene/Downloads/old IELTS/IELTS2015/KKo_3_1.txt\n",
      "/Users/irene/Downloads/old IELTS/IELTS2015/KKo_7_1.txt\n",
      "/Users/irene/Downloads/old IELTS/IELTS2015/KKo_8_1.txt\n",
      "/Users/irene/Downloads/old IELTS/IELTS2015/MTsy_20_1.txt\n",
      "/Users/irene/Downloads/old IELTS/IELTS2015/MTsy_34_1.txt\n",
      "/Users/irene/Downloads/old IELTS/IELTS2015/MTsy_4_1.txt\n",
      "/Users/irene/Downloads/old IELTS/IELTS2015/ZEv_13_1.txt\n",
      "/Users/irene/Downloads/old IELTS/IELTS2016/MTsy_2_1.txt\n",
      "/Users/irene/Downloads/exam/exam2015/KT_14_1.txt\n",
      "/Users/irene/Downloads/exam/exam2016/EKu_155_1.txt\n",
      "/Users/irene/Downloads/exam/exam2016/EKu_4_1.txt\n",
      "/Users/irene/Downloads/exam/exam2016/EKu_54_1.txt\n",
      "/Users/irene/Downloads/exam/exam2016/EKu_74_1.txt\n",
      "/Users/irene/Downloads/exam/exam2016/EKu_81_1.txt\n",
      "/Users/irene/Downloads/exam/exam2016/JSl_36_1.txt\n",
      "/Users/irene/Downloads/exam/exam2016/OR_40_1.txt\n",
      "/Users/irene/Downloads/exam/exam2016/OR_6_1.txt\n",
      "/Users/irene/Downloads/exam/exam2016/OR_95_1.txt\n",
      "/Users/irene/Downloads/exam/exam2016/ZEv_2_1.txt\n",
      "/Users/irene/Downloads/old IELTS/IELTS2016/OR_23_1.txt\n"
     ]
    }
   ],
   "source": [
    "for esse in esse_gr_lst:\n",
    "    #print(esse)\n",
    "    try:\n",
    "        path = re.search('(.+?);', esse).group(1)\n",
    "        #print(path)\n",
    "        path = re.sub('\\ufeff', '', path)\n",
    "        #parsed_text = get_parsed_text('english-partut-ud-2.0-170801.udpipe', path)\n",
    "        grade = re.search('.txt;([0-9]+)', esse).group(1)\n",
    "        grade2 = gr(grade)\n",
    "        #print(grade)\n",
    "        parsed_text = get_parsed_text('english-partut-ud-2.0-170801.udpipe', path)\n",
    "    # +++\n",
    "        num_tokens = count_tokens(parsed_text)# number of tokens\n",
    "    # +++\n",
    "        av_depth = av_depth_for_one_text(parsed_text)# average depth of tree\n",
    "    # +++\n",
    "        min_depth = min_depth_for_one_text(parsed_text)# minimal depth of tree\n",
    "    # +++\n",
    "        max_depth = max_depth_for_one_text(parsed_text)# maximal depth of tree\n",
    "    # +++\n",
    "        num_acl = count_acl(parsed_text)# number of acls\n",
    "        num_acl_relcl = count_acl_relcl(parsed_text)# number of acl:relcls\n",
    "        num_advcl = count_advcl(parsed_text)# number of advcls\n",
    "        num_sents = count_sent(parsed_text)# number of sentances\n",
    "        num_cl = count_clauses(parsed_text)# number of clauses\n",
    "        num_tu = count_tunits(parsed_text)# number of T-units\n",
    "    # +++\n",
    "        num_ctu = count_complex_tunit(parsed_text)# number of complex T-units\n",
    "    # +++\n",
    "        num_coord = count_coord(parsed_text)# number of coordinational phrases\n",
    "        num_np = count_np(parsed_text)# number of nps: possesive constructions, prepositional phrases, \n",
    "                                    #adj + nouns, gerund + inf, part + nouns \n",
    "        num_vp = count_vp(parsed_text)# number of vps\n",
    "    # +++\n",
    "        mean_l_sim = lemma_sim_mean(parsed_text)# mean L. distance (lemmas)\n",
    "    # +++\n",
    "        mean_p_sim = pos_sim_mean(parsed_text)# mean L. distance (pos)\n",
    "        mean_l_sim_nei = lemma_sim_mean2(parsed_text)\n",
    "    # +++\n",
    "        mean_p_sim_nei = pos_sim_mean2(parsed_text)\n",
    "        # +++\n",
    "        mean_tokens_root = tokens_befor_root(parsed_text)# number of tokens before root\n",
    "    # +++\n",
    "        n_inf = find_inf(parsed_text)\n",
    "    \n",
    "#--COMPLEX MEASURES--#\n",
    "        mean_length_s = mean_len_sent(parsed_text)# mean length of sentances\n",
    "        mean_length_c = num_tokens/num_cl\n",
    "        c_s = num_cl/num_sents\n",
    "        c_t = num_cl/num_tu\n",
    "        acl_t = num_acl/num_tu\n",
    "        acl_relcl_t = num_acl_relcl/num_tu\n",
    "        advcl_t = num_advcl/num_tu\n",
    "        acl_cl = num_acl/num_cl\n",
    "        acl_relcl_cl = num_acl_relcl/num_cl\n",
    "        advcl_cl = num_advcl/num_cl\n",
    "        coord_cl = num_coord/num_cl\n",
    "        t_s = num_tu/num_sents\n",
    "        poss_s = num_np[0]/num_sents\n",
    "        prep_s = num_np[1]/num_sents\n",
    "        adj_n_s = num_np[2]/num_sents\n",
    "        ger_inf_s = num_np[3]/num_sents\n",
    "        part_n_s = num_np[4]/num_sents\n",
    "        n_inf_s = n_inf/num_sents\n",
    "        vp_s = num_vp/num_sents\n",
    "\n",
    "        simple_measures = [num_tokens, num_acl, num_acl_relcl, num_advcl, num_sents, num_cl, num_tu, num_ctu,\n",
    "                       num_coord, num_np[0], num_np[1], num_np[2], num_np[3], num_np[4], n_inf, num_vp,\n",
    "                       min_depth, max_depth, sum(num_np)]\n",
    "    \n",
    "        measures = [av_depth, mean_l_sim, mean_p_sim, mean_l_sim_nei, mean_p_sim_nei,\n",
    "                mean_length_s, mean_length_c, c_s, c_t,\n",
    "                acl_t, acl_relcl_t, advcl_t, acl_cl, acl_relcl_cl, advcl_cl,\n",
    "                coord_cl, t_s, poss_s, prep_s, adj_n_s, ger_inf_s, part_n_s, n_inf_s,\n",
    "                vp_s, mean_tokens_root]\n",
    "        str_one_esse = ''\n",
    "        for measure in measures:\n",
    "            str_one_esse = str_one_esse + str(round(measure, 3)) + '\\t'\n",
    "        str_one_esse2 = ''\n",
    "        for m in simple_measures:\n",
    "            str_one_esse2 = str_one_esse2 + str(round(m, 4)) + '\\t'\n",
    "    #print(str_one_esse)\n",
    "        string = string + path + '\\t' + grade + '\\t' + grade2 + '\\t' + str_one_esse + '\\n'\n",
    "        string2 = string2 + path + '\\t' + grade + '\\t' + grade2 + '\\t' + str_one_esse2 + '\\n'\n",
    "    except:\n",
    "        print(path)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('/Users/irene/Desktop/Курсовая/res_measures1000_1.csv', 'w')\n",
    "f.write(string)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = open('/Users/irene/Desktop/Курсовая/res_measures_simple1000_1.csv', 'w')\n",
    "c.write(string2)\n",
    "c.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
